{
 "metadata": {
  "name": "",
  "signature": "sha256:0422387be911c0f1a0895c14fd710063954b38e9b14938fbc778774b82a43de2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "\n",
      "sys.path.append('toolbox/')\n",
      "#Change these paths to point to your neo and elephant directories\n",
      "sys.path.insert(1, 'toolbox/elephant')\n",
      "#sys.path.insert(1, '/home/denker/Projects/toolboxes/py/elephant')\n",
      "sys.path.insert(1, 'toolbox/python-neo')\n",
      "#sys.path.insert(1, '/home/denker/Projects/toolboxes/py/python-neo')\n",
      "\n",
      "import os.path\n",
      "import copy\n",
      "import numpy as np\n",
      "import scipy\n",
      "import scipy.io\n",
      "import scipy.signal\n",
      "import matplotlib.mlab\n",
      "import matplotlib.pyplot as plt\n",
      "import h5py\n",
      "\n",
      "import quantities as pq\n",
      "import neo\n",
      "import neo.io\n",
      "import elephant.stocmod\n",
      "import elephant.sta\n",
      "import elephant.surrogates\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "LFP and spike data in Python"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Implementing different spike-LFP measures"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this first section, we will become acquainted with different measures that relate spikes to the LFP. In particular, we will study the spike-triggered average (STA), and spike-LFP phase locking (PL) by means of artificially created data. To this end, spike trains are modeled either as Poisson or Gamma processes, whereas LFPs are modeled as sine waves. We will start by implementing the two methods, STA and PL.\n",
      "\n",
      "First, let's create some artificial data. Define a sampling rate (e.g., $f$=1000 Hz), the sampling period (1/sampling rate), and a time length $T$ for the artificial data (e.g., $T$=5 s). We'll create a Poisson spike train (represented by a `neo.Spiketrain` object that contains the spike times) and a sinusoidal LFP (represented as a `neo.Analogsignal`). Use reasonable parameters, for instance you might choose a spike rate of 10 Hz and an oscillation at 10 Hz.\n",
      "\n",
      "As you will learn tomorrow, a Poisson spike train is -- effectively -- random spike train at a specified rate. The function `elephant.stocmod.poisson(rate, tstop, tstart, n)` of `elephant` creates `n` Poisson processes of given start and stop times, and with an average firing rate `rate`. The spike trains are returned as a list\n",
      "\n",
      "Given below is a function that creates an artificial sinusoidal LFP given  time length of recording, sampling rate of the signal, the frequency, and the amplitude. The phase shift $\\Delta\\phi$ of the sinusoid $A \\sin (2\\pi ft+\\Delta\\phi)$ should is chosen randlomly. \n",
      "\n",
      "Plot your artificial LFP and spikes in a common plot (indicate spikes, e.g., by dots).\\\\"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_sine(tlength, srate, f, a):\n",
      "    \"\"\" Create a sine wave of length tlength, sampling rate srate, frequency f,\n",
      "        and amplitude a\"\"\"\n",
      "\n",
      "    #random phase of sine\n",
      "    p = np.random.rand() * 2 * np.pi\n",
      "\n",
      "    #check if sampling frequency is satisfied\n",
      "    if srate < 2 * f:\n",
      "        raise ValueError('Sampling theorem not met - increase sampling frequency to >2*Freq')\n",
      "\n",
      "    #create time vector\n",
      "    t=np.arange(\n",
      "        0,\n",
      "        tlength.magnitude,\n",
      "        1. / srate.rescale(1. / tlength.units).magnitude)\n",
      "\n",
      "    output = a * np.sin(2 * np.pi * f.rescale(1. / tlength.units).magnitude * t + p)\n",
      "\n",
      "    return neo.AnalogSignal(output*pq.dimensionless, t_start=0.*tlength.units, sampling_rate=srate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS: replace \"$$$\"s with proper expressions/codes\n",
      "\n",
      "#sampling rate: 1000 Hz\n",
      "samplingrate = $$$\n",
      "\n",
      "#sampling period in ms\n",
      "samplingperiod = $$$\n",
      "\n",
      "#rate of the Poisson: 10 Hz\n",
      "poisson_rate = $$$\n",
      "\n",
      "#length of simulated data segment: 5 sec\n",
      "timelength = $$$\n",
      "\n",
      "#frequency of LFP: 10 Hz\n",
      "#note that the frequency is the same as the rate for the Poisson process\n",
      "lfp_freq = $$$\n",
      "lfp_amp = 4    # arbitrary\n",
      "\n",
      "#create Poisson spike train\n",
      "st_poiss = elephant.stocmod.poisson($$$)[0]    # give appropriate arguments\n",
      "\n",
      "#create LFP sine wave\n",
      "lfp_sine = create_sine($$$)    # give appropriate arguments\n",
      "\n",
      "# write codes for plotting spikes and LFP on top of each other\n",
      "$$$"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Spike-triggered Average (STA)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now calculate the spike-triggered average (STA) of the artificial data. We will use the spike-triggered average method that comes with `elephant`, which requires as parameters: the vector containing the LFP time series `lfps`, the vector of spike times `spikes`, and the maximum lag $s$ to use for the STA `window` (i.e., how many milliseconds of LFP to cut out around each spike). The function returns the STA and corresponding time vector."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The straight-forward approach is to cut out pieces of LFP in a window of $\\pm s$ ms around time points of spiking, and then average the resulting time segments (can be selected using the option `method='average'`). If you chose 10 Hz as the LFP oscillation frequency, a good choice is $s$=200 ms since this choice includes about 4 periods of the oscillation (i.e., not too much, not too little). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STA lag in ms\n",
      "sta_lags = 200*pq.ms\n",
      "\n",
      "#remove spikes on border\n",
      "#st_poiss_reduced = st_poiss[numpy.logical_and(st_poiss>sta_lags_ms, st_poiss<timelength-sta_lags_ms)]\n",
      "\n",
      "sta1, time1 = elephant.sta.sta(lfp_sine, st_poiss, sta_lags, method='average')[0:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A second alternative is to first convert the spike train into a binned data structure. Here, spikes are represented by a binary vector, each of its entries represent a time bin (e.g., binned on a grid of width $h=$1 ms) and a value of $N$ denotes that $N$ spikes occurred in the corresponding time segment.\n",
      "\n",
      "Given this binary vector, the cross-correlation of the LFP signal and the binned process is the STA. An efficient way to calculate the correlation of two vectors $x$ and $y$ involves using the function\n",
      "\n",
      "    scipy.signal.correlate(x,y,mode='same')\n",
      "\n",
      "(passing as parameters 'mode=same' to indicate that the result has the same width as the two time series to correlate). The current elephant implementation of the sta uses the `method='correlation'` parameter to calculate the STA in this fashion."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#remove spikes on border\n",
      "#st_poiss_reduced = st_poiss[numpy.logical_and(st_poiss>sta_lags_ms, st_poiss<timelength-sta_lags_ms)]\n",
      "\n",
      "sta2, time2 = elephant.sta.sta(lfp_sine, st_poiss, sta_lags, method='correlation')[0:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Confidence of the spike-triggered average"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To calculate the confidence of the observed STA, we use a surrogate technique.\n",
      "\n",
      "- First, create 1000 STAs constructed from 1000 spike trains in which spikes are randomized in time (since we are dealing with stationary Poisson spike trains here, a simple shuffling procedure is adequate). This shuffling can be achieved using the routine `elephant.surrogates.spike_time_rand()`. \n",
      "- `append` each surrogate STA to a list.\n",
      "- Once all 1000 STAs are obtained, convert the list to an array using `np.array(x)`. For each time lag extract the 25th smallest and 25th largest value across all surrogate STAs (this results in 5\\% confidence, two-tailed). You can do so by sorting a matrix `x` that contains the 1000 values at each lag of the STA using `np.sort(x)`. Next, take the 25th and 975th row of the sorted matrix. Plotting these two values at each lag gives an estimate of the size of the STA when potential spike-LFP correlations are destroyed.\n",
      "- Write a function to implement this algorithm, and plot the 5% confidence limits along with the actual STAs calculated with the two methods above"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS\n",
      "def calc_sta_surrogate(lfp, spikes, window, nsurr, percentile):\n",
      "    #matrix of all STA's\n",
      "    stamat=[]\n",
      "\n",
      "    #calculate nsurr STAs\n",
      "    for i in range(nsurr):\n",
      "        output = elephant.sta.sta($$$)[0]    # give appropriate arguments\n",
      "        stamat.append(output)\n",
      "\n",
      "    #sort matrix individually for each time bin\n",
      "    stamat = np.sort(np.array(stamat), axis=0)\n",
      "\n",
      "    #find index rows lower and upper percentiles (divide percentile by two because of two-sided testing)\n",
      "    upper = int($$$)    # replace $$$ with an appropriate expression\n",
      "    lower = int($$$)    # replace $$$ with an appropriate expression\n",
      "\n",
      "    return (stamat[lower, :], stamat[upper, :])\n",
      "\n",
      "#Should be 1000, but that takes long...\n",
      "num_surrogate = 100\n",
      "\n",
      "(lsta, usta) = calc_sta_surrogate(lfp_sine, st_poiss, sta_lags, num_surrogate, 0.05)\n",
      "\n",
      "# plot sta1, sta2, lsta, and usta altogether\n",
      "$$$"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Is the STA significant? How does STA significance depend on the frequency of the sinusoid and spike train, on the length of the data, and on the number of surrogates performed?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Space for answer*"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Spike-triggered LFP phase"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, let's write a function to calculate the spike-triggered phase histogram using a direct decomposition of the signal into phase and amplitude. \n",
      "\n",
      "- To this end, calculate the analytic signal of the LFP series $x(t)$ as $$z(t)=x(t)+i H[x(t)]=A(t) \\exp(i \\phi(t))$$ with the Hilbert transform $H[.]$ by using the `scipy.signal.hilbert(x)` function (confusingly, despite its name, this function directly calculates the analytic signal $z(t)$, not the Hilbert transformation). \n",
      "- Using the functions `numpy.angle()` and `numpy.abs()`, extract the phase $\\phi(t)$ and amplitude $A(t)$, respectively, of the oscillation of the returned analytic signal $z(t)$. \n",
      "\n",
      "Hint: You can directly create these as new neo.AnalogSignal, retaining start, sampling_rate and any annotations:\n",
      "\n",
      "    >>> old_signal = neo.AnalogSignal([1, 2, 3]*pq.uV, t_start=0.*pq.ms, sampling_rate=1000.*pq.Hz)\n",
      "    >>> new_signal = old_signal.duplicate_with_new_array([3, 4, 5]*pq.dimensionless)\n",
      "    >>> print new_signal.magnitude\n",
      "    [3, 4, 5]\n",
      "    >>> print new_signal.sampling_rate\n",
      "    1000. Hz\n",
      "    \n",
      "- We may also backtrack to obtain the Hilbert transform as the imaginary part of the analytic signal (use `numpy.imag()` on the analytic signal magnitude). \n",
      "- Visualize the simulated LFP signal, its Hilbert transform, the amplitude and the phase as a function of time. Note: \\texttt{angle()} returns phase angles between $-\\pi$ and  $\\pi$. What does a phase of 0 correspond to with respect to the original signal? What does phase 0 correspond to on the Hilbert signal? In the following we stick to this definition of phase."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS: replace \"$$$\"s with proper expressions\n",
      "#Calculate hilbert transform and analytic signal\n",
      "lfp_sine_analytic = lfp_sine.duplicate_with_new_array(scipy.signal.hilbert(lfp_sine.magnitude)*pq.dimensionless)\n",
      "lfp_sine_hilb = $$$\n",
      "\n",
      "lfp_sine_phase = $$$\n",
      "lfp_sine_amp = $$$\n",
      "\n",
      "#Plot the obtained analytic signal related measures nicely\n",
      "$$$"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Finally, calculate the phase and amplitude at the spike times. To this end, use the calc_phase_amp function provided below, which takes the analytic signal as a neo AnalogSignal, and the SpikeTrain. \n",
      "- Plot these spike-triggered phase and amplitude distributions.\n",
      "\n",
      "*Side note*: If you want to be very precise in the calculation of the spike-triggered phase when a spike occurs between two sample time points $t_i$  and $t_{i+1}$ for which the phase $\\phi(t)$ of the LFP was calculated, you might want to circularly interpolate the phase between these two neighboring bins:\n",
      "$$\\phi(t)=\\arg ( \\exp( i ( \\phi(t_i) + \\frac{t-t_i }{t_i+1-t_i} (\\phi(t_i+1)-\\phi(t_i)) ) ) )$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calc_phase_amp(analytic_sig, spikes):\n",
      "    '''\n",
      "    Calculate the spike-triggered phases.\n",
      "    \n",
      "    analytic_signal: neo.AnalogSignal \n",
      "        The analytic signal from which to calculate the phase\n",
      "    spikes: neo.SpikeTrain\n",
      "        The spike times\n",
      "        \n",
      "    Returns:\n",
      "        (phases,amps)\n",
      "            Arrays of phases and amplitudes at spike times, respectively.\n",
      "    '''\n",
      "    phases = []\n",
      "    amp = []\n",
      "    for t in spikes:\n",
      "        # find index in LFP vector where the spike occurrs\n",
      "        sttime = np.argmin(np.abs(t - analytic_sig.times))\n",
      "\n",
      "        # get corresponding phase and amplitude\n",
      "        phases.append(np.angle(analytic_sig.magnitude)[sttime])\n",
      "        amp.append(np.abs(analytic_sig.magnitude)[sttime])\n",
      "\n",
      "    return (np.array(phases), np.array(amp))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# STUDENTS\n",
      "(sinephase, sineamp) = calc_phase_amp($$$)    # give proper arguments\n",
      "\n",
      "# Plot the histograms of `sinephase` and `sineamp`\n",
      "$$$"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now assume a gamma spike train of rate $f$ and order $N$ by creating a Poisson spike train of rate $Nf$ and keeping only every $N$-th spike of the spike train. Increase the duration of the simulated recording to obtain a good estimate. Does the regularity of the process induce locking if you vary the parameters for finite data stretches? What happens as the recording length is increased?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS: repaet the same analysis with a gamma spike train instead of a Poisson spike train\n",
      "$$$"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Analysis of spike-LFP phase locking in recordings from motor cortex"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this second task of this notebook you can apply the phase locking method to cortical data. We will look at one specific experimental condition during which the LFP activity was recorded in parallel to one spiking neuron. We will try to detect whether a recorded neuron shows a non-uniform distribution of spike-triggered LFP phases."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Load the data files `data/spikes1.mat` and `/data/lfp1.mat` (the latter you already know). \n",
      "\n",
      "The former contains a so called Matlab cell array `spike_cell` of $N$ dimensions. This cell array is a data structure that does not exist in python. The scipy loading routine thus creates a replacement list/array structure that nevertheless allows access to the data. The spike times of trial $i$ can be obtained using\n",
      "\n",
      "    spikes1=scipy.io.loadmat('data/spikes1.mat')\n",
      "    spikes=spikes1['spike_cell']  # get spike_cell variable\n",
      "    spiketimes=spikes[i][0][0]  # vector of times of spikes of trial i in ms\n",
      "    firstspiketime=spikes[i][0][0][0]  # first spike time of trial i in ms\n",
      "\n",
      "- Create an AnalogSignal and a SpikeTrain object for each of the data (see previous exercise)\n",
      "- Plot the spike data (a spike raster, using dots or lines) and the LFP traces into one plot, and compare them (reuse some of the code you wrote earlier!). For the LFP, it is again helpful for visualization to normalize amplitudes using a z-transform: subtract the mean from each waveform, and divide by the standard deviation (also see previous exercise)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_lfp_spike(seg, spacing=5, offset=0, color=''):\n",
      "    '''\n",
      "    Plot LFPs and corresponding spikes in a Segment.\n",
      "    Assumes trials are identified by the annotation\n",
      "    trial_id on SpikeTrains and AnalogSignals\n",
      "    \n",
      "    seg: container for analog signals and spike trains\n",
      "    offset: vertical spacing between two LFP signals\n",
      "    color: color to use for plotting\n",
      "    '''\n",
      "    for asig in seg.analogsignals:\n",
      "        plt.plot(asig.times.magnitude, asig.magnitude + asig.annotations['trial_id'] * spacing + offset, color)\n",
      "    for st in seg.spiketrains:\n",
      "        plt.plot(st, [st.annotations['trial_id'] * spacing + offset for j in range(len(st))], '.')\n",
      "    \n",
      "    # define plot parameters for x-axis\n",
      "    plt.xlabel('t ({0})'.format(asig.times.dimensionality), size=16)\n",
      "    xmin, xmax = min(se.analogsignals[0].times.magnitude), max(asig.times.magnitude)\n",
      "    plt.xlim(xmin, xmax)\n",
      "    # define plot parameters for y-axis\n",
      "    plt.ylabel('trials', size=16)\n",
      "    ymin, ymax = 0, len(seg.analogsignals)*spacing\n",
      "    plt.ylim(ymin, ymax+1)\n",
      "    yticks = np.arange(ymin-spacing, ymax+1, spacing*10)\n",
      "    yticklabels = [str(i) for i in np.arange(1, len(seg.analogsignals)+1, 10, dtype=int)]\n",
      "    plt.yticks(yticks, yticklabels)\n",
      "    plt.xlabel('t ({0})'.format(asig.times.dimensionality), size=16)\n",
      "    plt.ylabel('trials', size=16)\n",
      "    \n",
      "def perform_zscore(input_seg):\n",
      "    '''\n",
      "    This function normalizes AnalogSignals in a Segment input_seg.\n",
      "    '''    \n",
      "    for asig in input_seg.analogsignals:\n",
      "        #STUDENTS: implement this block\n",
      "        $$$"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS: implement what's written in the comments\n",
      "\n",
      "# Load LFP data\n",
      "$$$\n",
      "\n",
      "# Load spike data\n",
      "$$$\n",
      "\n",
      "# Create neo.Segment object for LFP data\n",
      "$$$\n",
      "\n",
      "# Create neo.SpikeTrain object for spike data\n",
      "$$$\n",
      "\n",
      "# Create missing links in the Segment object\n",
      "$$$\n",
      "\n",
      "#Normalize LFP\n",
      "$$$\n",
      "\n",
      "#Plot LFPs and spikes\n",
      "$$$"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Filtering the LFP signal"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In contrast to the first tasks of this module, we do not have a nice harmonic, artificial LFP signal. In reality, LFPs are often rather complex signals composed of different frequency contributions. Therefore, to estimate the relationship of spikes to the LFP, you typically need to first filter the signal in a frequency range of interest.\n",
      "\n",
      "We'll use a Butterworth filter to filter each LFP trial separately. To this end, we first use the `scipy.signal.butter()` function to obtain a set of filter coefficients. As `order` of the filter (number of coefficients) a value of 5 should be sufficient (alternatively, the function `scipy.signal.butterord()` yields an estimate of the optimal order). You can design a bandpass filter between `a` Hz and `b` Hz using\n",
      "\n",
      "    (coeffb,coeffa)=scipy.signal.butter(order,np.array([a,b])*2.0/sf,'pass')\n",
      "\n",
      "where `sf` is the sampling frequency (which is contained in the `AnalogSignal` structure). The return value are the filter coefficients that realize this particular type of filter.\n",
      "\n",
      "The vector `[a,b]` is multiplied by $2/\\mathrm{s_f}$ since the filter frequencies are given in units of the Nyquist frequency, which is half the sampling frequency.\n",
      "\n",
      "- For `a` and `b` choose a frequency window to select the beta band around approx. `16 Hz` (see power spectrum of the previous notebook). Use the above function to calculate the filter coefficients for the filter.\n",
      "\n",
      "Butterworth filters are part of a class of filters (IIR) that does not preserve phase information, i.e., the filtered signal is shifted in time, but each frequency by different amounts. Therefore, we must be careful to apply an appropriate filter technique that corrects for the phase distortions of the filter, i.e., a filter algorithm that is phase neutral.\n",
      "\n",
      "A good way to achieve such neutrality this is to use the function `scipy.signal.filtfilt()` (instead of the more basic routine `lfilter()`). Technically, it implements a zero-phase filtering technique by applying the filter a second time in a time-reversed manner, thus canceling any phase shifts induced by filtering. Both filter routines take the coefficients returned by `butter()` as argument:\n",
      "\n",
      "    filtered_signal=scipy.signal.lfilter(coeffb,coeffa,signal)\n",
      "    filtered_signal=scipy.signal.filtfilt(coeffb,coeffa,signal)\n",
      "\n",
      "\n",
      "In summary of the above, find here the code of a routine that filters an `AnalogSignal` object `signal`  Hz in a band between `lowpass` Hz and `highpass` Hz:\n",
      "\n",
      "    def filtersignal(signal,lowpass,highpass):\n",
      "        order = 5\n",
      "        (b, a) = scipy.signal.butter(\n",
      "            order,\n",
      "            np.array([lowpass,highpass])*2.0/signal.sampling_rate,\n",
      "            btype='pass')\n",
      "    return scipy.signal.filtfilt(b, a, signal.magnitude)\n",
      "\n",
      "\n",
      "- Filter all LFP trials using this approach.\n",
      "- Plot the resulting `filtfilt()` filtered LFP traces. Compare these to the unfiltered LFPs and to LFPs filtered using the `lfilter()` function (instead of `filtfilt()`). Estimate by eye the phase lag introduced by `lfilter()` at the beta frequency -- is it constant in time?\n",
      "- Try various pass bands based on the power spectrum of the LFPs: what would be a good choice?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS\n",
      "def plot_lfp(seg, spacing=5, offset=0, color='', **kwargs):\n",
      "    '''\n",
      "    Plot LFPs in a Segment.\n",
      "    Assumes trials are identified by the annotation\n",
      "    trial_id on AnalogSignals\n",
      "    \n",
      "    seg: container for analog signals\n",
      "    offset: vertical spacing between two LFP signals\n",
      "    color: color to use for plotting\n",
      "    **kwargs: additional arguments passed to plot()\n",
      "    '''\n",
      "    # implement this function\n",
      "    $$$\n",
      "\n",
      "#This function filters a signal with a band pass between lowpass and highpass Hz.\n",
      "#The signal is sampled at samplingfreq Hz.\n",
      "def filtersignal(signal, lowpass, highpass):\n",
      "    # implement this function\n",
      "    $$$\n",
      "\n",
      "#Same as above, but using lfilter() instead of filtfilt()\n",
      "def filtersignal_simple(signal, lowpass, highpass):\n",
      "    # implement this function\n",
      "    $$$\n",
      "\n",
      "#Filter LFP trial by trial\n",
      "seg1_filt = copy.deepcopy(seg1)\n",
      "seg1_filtfilt = copy.deepcopy(seg1)\n",
      "\n",
      "for asig in seg1_filtfilt.analogsignals:\n",
      "    asig = filtersignal($$$)*pq.dimensionless    # give appropriate arguments to filter LFP between 11 and 21 Hz\n",
      "for asig in seg1_filt.analogsignals:\n",
      "    asig = filtersignal_simple($$$)*pq.dimensionless    # give appropriate arguments to filter LFP between 11 and 21 Hz\n",
      "    \n",
      "# plot the original and the filtered LFPs\n",
      "$$$"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Spike-triggered phase"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Finally, calculate the spike-triggered phases for each trial of the filtered LFP, using the `calc_phase_amp()` function used above.\n",
      "- Calculate the histogram of spike phases (pooled across trials) using the `scipy.histogram()`, with a phase axis from $0$ to $2\\pi$ binned at, e.g., 25 bins.  Normalize the result by the number of spikes (such that the histogram has unit area).\n",
      "- Plot the resulting phase histogram via the `plt.bar()` function.\n",
      "- Repeat the analysis with the unfiltered band and compare the results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Pool spike triggered phases and amplitudes across trials, and save all values consecutively in\n",
      "#the vectors pl an al, respectively\n",
      "pl = np.array([])\n",
      "al = np.array([])\n",
      "for asig in seg1_filtfilt.analogsignals:\n",
      "    (phase, amp) = calc_phase_amp(\n",
      "        asig.duplicate_with_new_array(\n",
      "            scipy.signal.hilbert(asig.magnitude)),\n",
      "        seg1_filtfilt.filter(trial_id=asig.annotations['trial_id'], objects='SpikeTrain')[0])\n",
      "    pl = np.concatenate((pl, phase))\n",
      "    al = np.concatenate((al, amp))\n",
      "\n",
      "#Create an axis for the histogram\n",
      "phase_axis = np.linspace(-np.pi, np.pi, 25)\n",
      "\n",
      "#Plot the phase and amplitude distributions\n",
      "plt.figure()\n",
      "plt.suptitle('phase and amplitude distribution (pooled across trials)', size=18)\n",
      "plt.subplot(211)\n",
      "histogramcounts, histogramedges = scipy.histogram(pl, phase_axis)\n",
      "plt.bar(histogramedges[:-1], histogramcounts, width=2*np.pi/25.)\n",
      "plt.xlabel('phase (rad)', size=12)\n",
      "plt.ylabel('counts', size=12)\n",
      "plt.subplot(212)\n",
      "plt.hist(al)\n",
      "plt.xlabel('amplitude (\\muV)', size=12)\n",
      "plt.ylabel('counts', size=12)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To estimate the parameters of the histogram, fit a von Mises distribution to the data. The functional form of the fit function, the von-Mises distribution, is given by:\n",
      "\n",
      "    y = P[2] + np.exp(P[1] * np.cos(x - P[0])) / 2.0 / np.pi / np.special.j0(P[1])\n",
      "\n",
      "where `P` is a 3 element vector of the parameters `P[0]`=$a$ (peak location of the distribution) and `P[1]`=$\\kappa$ (corresponds to the width of the distribution) and an offset `P[2]`. \n",
      "\n",
      "Use the fitting function `scipy.optimize.leastsq()` to find optimal parameters $\\kappa$ and $a$ and plot the best fit into the histogram."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS\n",
      "def Mise(P,x):\n",
      "    # implement this function to return the von-Mises distribution\n",
      "    $$$\n",
      "\n",
      "def errorfunc(P, x, y):\n",
      "    return y - Mise(P, x)\n",
      "\n",
      "p0 = [0, 0.001, 10]\n",
      "\n",
      "p_est = scipy.optimize.leastsq(errorfunc, p0, args=(histogramedges[0:-1], histogramcounts))\n",
      "print p_est\n",
      "\n",
      "# plot the histogram and the fit curve\n",
      "$$$"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Acknowledgements"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data are courtesy of Dr. Alexa Riehle, Institut de Neurosciences de la Timone (INT), UMR 7289, CNRS - Aix Marseille Univ., Marseille, France."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
