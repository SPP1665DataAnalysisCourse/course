{
 "metadata": {
  "name": "",
  "signature": "sha256:904ff1c6008ada798cee418248429706bbfc9b116de2a888dbf403de9af7e371"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "\n",
      "#Change these paths to point to your neo directory\n",
      "#sys.path.insert(1,'toolbox/python-neo')\n",
      "sys.path.insert(1,'/home/denker/Projects/toolboxes/py/python-neo')\n",
      "\n",
      "import os.path\n",
      "import numpy as np\n",
      "import scipy\n",
      "import scipy.io\n",
      "import scipy.signal\n",
      "import matplotlib.mlab\n",
      "import matplotlib.pyplot as plt\n",
      "import h5py\n",
      "\n",
      "import quantities as pq\n",
      "import neo\n",
      "import neo.io\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Working with LFP data in Python"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading Matlab data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the following exercises we will load, visualize and analyze (parallel) LFP data from an actual electrophysiological recording. Data from experimental electrophysiology labs is frequently exchanged in the Matlab `.mat` file format. Luckily, `scipy` supplies ready-made functions to load and save data `x` from/to this file type:\n",
      "\n",
      "    x=scipy.io.loadmat(filename)\n",
      "    scipy.io.savemat(filename,x)\n",
      "\n",
      "Use these functions to load the data file `lfp1.mat` in the `data` subdirectory. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename = os.path.sep.join(['data', 'lfp1.mat'])\n",
      "print \"Loading {0}\".format(filename)\n",
      "lfp1=scipy.io.loadmat(filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Inspect the return value. Use the `type()` function to inspect which data type it is (see example below)!  Use `lfp1.keys()` to check which fields are in the returned data!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENT\n",
      "# Example on how to inspect the data types of a variable\n",
      "\n",
      "a = 5\n",
      "print a, type(a) == int\n",
      "print a, type(a)\n",
      "print a, type(a).__name__ # convert the type to a string object that can be printed\n",
      "\n",
      "a = 6.\n",
      "print a, type(a).__name__\n",
      "\n",
      "a = {'s': \"Hello!\", 't': \"World!\"}\n",
      "print a, type(a).__name__\n",
      "print a.keys()\n",
      "print a.values()\n",
      "print a, type(a['s']).__name__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# STUDENT\n",
      "print type(lfp1)\n",
      "print lfp1.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write a routine that prints the contents and data types of the saved file in a nice format. To determine the type of each variable, again use `type()`. To print out the dimensions of a matrix, i.e., an numpy array, use `.shape`, e.g.\n",
      "\n",
      "    a=np.array([[1,2,3],[4,5,6]])\n",
      "    print a.shape"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Print contents of lfp1\n",
      "for k in lfp1.keys():\n",
      "    if k not in ['__version__', '__header__', '__globals__']:\n",
      "        print \"{0}: type={1}, shape={2}\".format(k, type(lfp1[k]).__name__, lfp1[k].shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data you have loaded contains three interesting variables contained in the dictionary under the keys `time`, `sf`, and `lfp_matrix`. The latter contains the actual LFP signal, where rows are the individual trials of an experiment, and columns are the time bins corresponding to the trial time stored in `time` (in ms). Finally, `sf` contains the sampling frequency in Hz. \n",
      "\n",
      "As you saw, all data objects are returned as two-dimensional matrices from the `.mat` format when using the `scipy.io.loadmat()` function. To make our life easier, let's define a few variables that contain only the relevant dimensions of each variable (`lfp_matrix`: 2-D, `time`: 1-D, `sf`: 0-D, i.e.just a number)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lfpmat1=lfp1['lfp_matrix']\n",
      "time1=lfp1['time'][0]\n",
      "sf1=lfp1['sf'][0][0]\n",
      "\n",
      "# tip: the following code loads .mat data suppressing irrelevant array dimensions\n",
      "#\n",
      "#lfp1=scipy.io.loadmat(filename, squeeze_me=True)\n",
      "#lfpmat1 = lfp1['lfp_matrix']\n",
      "#time1 = lfp1['time']\n",
      "#sf1 = lfp1['sf']\n",
      "#\n",
      "\n",
      "print type(lfpmat1), lfpmat1.shape\n",
      "print type(time1), time1.shape\n",
      "print type(sf1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Converting data to Neo"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"base_schematic.png\" width=\"600px\" />\n",
      "Now, let's put the data in Neo containers so that we work on a well defined data structure. The figure (see Garcia et al, 2014) reminds you of the overall Neo schematic.\n",
      "\n",
      "To keep it simple, let us construct a `neo.AnalogSignal` object for each LFP, and a `neo.Segment` object named `seg` to group the LFPs together.\n",
      "\n",
      "Note that we do not need to retain the `time1` vector of time stamps -- the Neo object only saves the first time point and the sampling period (or frequency), which is sufficient to reconstruct the time bins on-the-fly.\n",
      "\n",
      "After creating Neo objects, call the `create_relationship()` method of the top level object (here: the `neo.Segment`) in order to create all missing links between objects (e.g., segement points to its associated analog signals, and vice versa each analog signal points back to its parent segment).\n",
      "\n",
      "The quantities library is imported as `pq`. Thus all common units, such as milliseconds, are accessible via constructs such as `pq.ms`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seg1 = neo.Segment(name=\"LFP_1\")\n",
      "for i in range(lfpmat1.shape[0]):\n",
      "    asig = neo.AnalogSignal(\n",
      "        lfpmat1[i]*pq.uV, \n",
      "        t_start = time1[0]*pq.ms,\n",
      "        sampling_rate = sf1*pq.Hz,\n",
      "        channel_index = 1)\n",
      "    \n",
      "    # Annotate the trial number\n",
      "    asig.annotate(trial_id = i)\n",
      "    \n",
      "    # Append the signal to the segment\n",
      "    seg1.analogsignals.append(asig)\n",
      "\n",
      "# Create missing links\n",
      "seg1.create_relationship()\n",
      "\n",
      "# Print information on the first analog signal\n",
      "seg1.analogsignals[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, let's save the Neo object we have created. To this end, let us use the HDF5 I/O of neo. HDF5 is an emerging open standard file format that can be read by many applications, including Matlab."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hdf_file = neo.io.hdf5io.NeoHdf5IO(filename='LFP1.hdf5')\n",
      "hdf_file.save(seg1)\n",
      "hdf_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Visualizing the LFP"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Normalize LFP"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a first task, write a function that performs a $z$-transform of the data, that is, subtract the mean of each trial, and divide by its standard deviation (`np.mean()` and `np.std()`): $$s \\rightarrow \\frac{s-\\bar s}{\\sigma_{s}}$$ \n",
      "\n",
      "In practice, use `asig.magnitude` to pass the array data stripped of its quantity to any numpy functions! The resulting $z$-transformed signal should get the quantity `pq.dimensionless`.\n",
      "\n",
      "This procedure eliminates ultra-slow drifts in the LFP signal, and accounts for variations in the oscillation amplitude over the time course of the experiment."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def perform_zscore(input_seg):\n",
      "    '''\n",
      "    This function normalizes AnalogSignals in a Segment input_seg.\n",
      "    '''\n",
      "    for asig in input_seg.analogsignals:\n",
      "        #STUDENTS\n",
      "        asig_mag = asig.magnitude\n",
      "        # vvv from here vvv\n",
      "        sigmean = np.mean(asig_mag, axis=0)\n",
      "        sigstd = np.std(asig_mag, axis=0)\n",
      "        sigz = (asig_mag - sigmean) / sigstd\n",
      "        # ^^^ to here ^^^\n",
      "        asig.data = sigz * pq.dimensionless\n",
      "        \n",
      "perform_zscore(seg1)\n",
      "\n",
      "seg1.analogsignals[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Why is it not necessary that the function `perform_zscore` returns the result? What happened to the data we originally loaded? What is the advantage and disadvantage of handling operations *inplace* using this approach?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Space for answer*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If the original data should be retained, you could use\n",
      "\n",
      "    asig_new = asig.duplicate_with_new_array(new_array)\n",
      "    \n",
      "which creates a new AnalogSignal object with the same information as the original one, except for the actual data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Plot LFPs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now use the function below to nicely plot the normalized LFP traces of all trials. We do not just plot them on top of each other, else one will not be able to see anything.\n",
      "\n",
      "The `enumerate` function below is useful in this context. Employed in a for-loop it allows to step through the data (here in `asig`) and keep a count of it (here in `i`).\n",
      "\n",
      "Write code to plot our loaded LFPs. Use the command `%matplotlib qt` to see the output in a new window rather than in this notebook. This way you can zoom and pan the data, which is useful for inspection.\n",
      "\n",
      "Make your plots nice using commands such as `plt.suptitle()`, `plt.axis()`, `plt.xlabel()`, which are all quite similar to their Matlab equivalents.\n",
      "\n",
      "Note: Use `%matplotlib inline` to show figures inline, and `%matplotlib qt` to show them as a separate figure!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_lfp(seg, spacing=5, offset=0, color=''):\n",
      "    '''\n",
      "    Plot LFPs in a Segment.\n",
      "    Assumes trials are identified by the annotation\n",
      "    trial_id on AnalogSignals\n",
      "    \n",
      "    seg: container for analog signals\n",
      "    offset: vertical spacing between two LFP signals\n",
      "    color: color to use for plotting\n",
      "    '''\n",
      "    for asig in seg.analogsignals:\n",
      "        plt.plot(asig.times.magnitude, asig.magnitude + asig.annotations['trial_id'] * spacing + offset, color)\n",
      "        xmin, xmax = min(asig.times.magnitude), max(asig.times.magnitude)\n",
      "\n",
      "    # define plot parameters for x-axis\n",
      "    plt.xlabel('t ({0})'.format(asig.times.dimensionality), size=16)\n",
      "    # define plot parameters for y-axis\n",
      "    plt.ylabel('trials', size=16)\n",
      "    ymin, ymax = 0, len(seg.analogsignals)*spacing\n",
      "    plt.ylim(ymin, ymax+1)\n",
      "    yticks = np.arange(ymin-spacing, ymax+1, spacing*10)\n",
      "    yticklabels = [str(i) for i in np.arange(1, len(seg.analogsignals)+1, 10, dtype=int)]\n",
      "    plt.yticks(yticks, yticklabels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS\n",
      "plt.figure(1)\n",
      "plt.suptitle('Normalized LFP traces', size=18)\n",
      "plot_lfp(seg1)\n",
      "plt.axis('tight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compare this plot to the individual non-$z$-transformed signals. To this end, recreate a new `Segment` nameed `seg_org` based on the original data in lfpmat1 just like above, and use the `plot_lfp()` function to plot them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS\n",
      "raw_seg1 = neo.Segment(name=\"LFP_1\")\n",
      "for i in range(lfpmat1.shape[0]):\n",
      "    asig = neo.AnalogSignal(\n",
      "        lfpmat1[i]*pq.uV, \n",
      "        t_start = time1[0]*pq.ms,\n",
      "        sampling_rate = sf1*pq.Hz,\n",
      "        channel_index = 1)\n",
      "    \n",
      "    # Annotate the trial number\n",
      "    asig.annotate(trial_id = i)\n",
      "    \n",
      "    # Append the signal to the segment\n",
      "    raw_seg1.analogsignals.append(asig)\n",
      "\n",
      "# Create missing links\n",
      "raw_seg1.create_relationship()\n",
      "\n",
      "plt.figure(1)\n",
      "plt.suptitle('Non-Normalized LFP traces', size=12)\n",
      "plot_lfp(raw_seg1, spacing=50)\n",
      "plt.axis('tight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Describe the signals! Which frequency components (which bands) do you expect based on the traces? Are the frequencies constant in time? Can you say something about the cross-trial stationarity or variability?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Space for answer*"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Spectral analysis"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Power spectrum of the LFP"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To better understand the frequency composition in the data, let's create a power spectrum in a new figure created with `plt.figure()`. To this end, use\n",
      "\n",
      "    matplotlib.mlab.psd()  \n",
      "\n",
      "and plot the result in a semilogarithmic fashion (Hint: User `pyplot.semilogy()` to plot the result). The `psd` function does not contain the concept of trials in order to obtain a trial-averaged power spectrum. You could of course just use the `psd` function to calculate the spectra of the individual trials (rows of the LFP matrix) and then average these using `numpy.mean()`. But much easier yet, we'll first concatenate all trials into one long vector and use this vector as input time series to the `psd()` function. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Concatenate all arrays\n",
      "concats = np.array([])\n",
      "for asig in seg1.analogsignals:\n",
      "    concats = np.hstack([concats, asig.magnitude])\n",
      "    \n",
      "# Build concatenated signal\n",
      "concat_sig1 = neo.AnalogSignal(\n",
      "    concats * pq.mV,\n",
      "    t_start = seg1.analogsignals[0].t_start,\n",
      "    sampling_period = seg1.analogsignals[0].sampling_period)\n",
      "    \n",
      "# STUDENTS\n",
      "plt.figure()\n",
      "plt.suptitle('LFP power spectrum', size=18)\n",
      "(p1, f1) = matplotlib.mlab.psd(concat_sig1.magnitude, NFFT=256, Fs=sf1)\n",
      "plt.semilogy(f1, p1)\n",
      "plt.xlim([1, 100])\n",
      "plt.xlabel('f (Hz)', size=16)\n",
      "plt.ylabel('power density (1/Hz)', size=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the NFFT parameter of `psd()` you can vary the number of sample points used to calculate the power spectrum. See how this parameter changes the resolution of the frequency axis, and the quality of the estimate. What would be the maximum sensible parameter for NFFT given the data length (use the `len()` function)? Does is actually make sense?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Describe what you see! How does this spectrum match the plot of the LFP?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Space for answer*"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Trial averaged power spectrum"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we look closely at the signal traces, you may find that the frequency composition changes with trial time. Create a spectrogram (time-resolved power spectrum) using\n",
      "\n",
      "    matplotlib.mlab.specgram()\n",
      "\n",
      "Usage of the `specgram` function is somewhat similar to psd, but here the temporal domain comes into play: The spectra are calculated in a sliding time window of length `NFFT` sample points. In order to obtain a trial-averaged spectrum, unlike in 2d), you will need to calculate the spectrogram matrix (time x freq) for each trial individually, and then average across the matrices of each trial.\n",
      "You can use\n",
      "\n",
      "    pyplot.pcolor()\n",
      "\n",
      "to make a plot of the resulting trial-averaged power (coded in color) as a function of time (x-axis) and frequency (y-axis). For better visibility, it is again advisable to plot not the resulting matrix itself, but the logarithm of the power (`numpy.log`).\n",
      "The `noverlap` parameter of `specgram` lets you vary the resolution of the time axis, specifying by how many (of maximally `NFFT-1`) bins two consecutive sliding windows overlap.\n",
      "\n",
      "Play around with the parameters to obtain a good representation!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS: remove values for NFFT and noverlap\n",
      "# Store time resolved power spectrum in ptr1, frequencies in ftr1, time stamp vector in ttr1\n",
      "for i, asig in enumerate(seg1.analogsignals):\n",
      "    (ptr1temp, ftr1, ttr1) = matplotlib.mlab.specgram(asig.magnitude, NFFT=256, noverlap=250, Fs=sf1)\n",
      "\n",
      "    if i==0:\n",
      "        ptr1 = ptr1temp.copy()\n",
      "    else:\n",
      "        ptr1 = ptr1 + ptr1temp\n",
      "\n",
      "x_min = seg1.analogsignals[0].t_start.rescale('ms').magnitude\n",
      "ttr1 = ttr1 * 1000. + x_min\n",
      "ptr1 = ptr1 / len(seg1.analogsignals)\n",
      "plt.figure()\n",
      "plt.suptitle('LFP 1 spectrogram', size=18)\n",
      "plt.pcolor(ttr1, ftr1, np.log(ptr1))\n",
      "plt.xlabel('t ({0})'.format(asig.t_start.dimensionality), size=16)\n",
      "plt.ylabel('f (Hz)', size=16)\n",
      "plt.axis('tight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Describe the temporal structure of the oscillations! Which bands are prominent at which time? Can you associate the power to features observed in the raw data?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Space for answers*"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Save results of spectral analysis to disk"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For later reference, let's save our results as HDF5 file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = h5py.File('results.hdf5', 'w')\n",
      "f['power_f1'] = f1\n",
      "f['power_P1'] = p1\n",
      "f['power_tr_t1'] = ttr1\n",
      "f['power_tr_f1'] = ftr1\n",
      "f['power_tr_P1'] = ptr1\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Analysis of multiple LFPs"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Loading and visualizing a second data trace"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the file `lfp2.mat` in the `data` subdirectory you will find another stretch of LFP data. It was recorded simultaneously with the one you have looked at before, but from an electrode about 400$\\mu$m away. While a single spike is typically only observed on one of two electrodes this far apart, LFPs may very well show a strong resemblance at these distances.\n",
      "\n",
      "- Load the data and create a new Neo Segment `seg2`\n",
      "- $z$-transform `seg2`\n",
      "- As a first step, use the plotting function developed earlier to make a simultaneous visualization of LFP 1 and 2 that is suitable to show how similar individual trials (rows) of the two LFPs are.\n",
      "- Examine the power spectrum of LFP 2!\n",
      "- In how far are the two signals similar? In how far do they differ? What could be the resasons?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Space for answer*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#all below: STUDENT\n",
      "filename = 'lfp2'\n",
      "lfp2 = scipy.io.loadmat('data/{0}.mat'.format(filename))\n",
      "\n",
      "#For convenience\n",
      "time2 = lfp2['time'][0]\n",
      "lfpmat2 = lfp2['lfp_matrix']\n",
      "sf2 = lfp2['sf'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seg2 = neo.Segment(name=\"LFP_2\")\n",
      "for i in range(lfpmat2.shape[0]):\n",
      "    asig = neo.AnalogSignal(\n",
      "        lfpmat2[i]*pq.uV, \n",
      "        t_start = time2[0]*pq.ms,\n",
      "        sampling_rate = sf2*pq.Hz,\n",
      "        channel_index = 2)\n",
      "    \n",
      "    # Annotate the trial number\n",
      "    asig.annotate(trial_id = i)\n",
      "    \n",
      "    # Append the signal to the segment\n",
      "    seg2.analogsignals.append(asig)\n",
      "\n",
      "# Create missing links\n",
      "seg2.create_relationship()\n",
      "\n",
      "# Print information on the first analog signal\n",
      "seg2.analogsignals[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Normalize LFP\n",
      "perform_zscore(seg2)\n",
      "\n",
      "seg2.analogsignals[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure()\n",
      "plt.suptitle('LFPs at neighbouring electrodes', size=18)\n",
      "plot_lfp(seg1, offset=0, color='r')\n",
      "plot_lfp(seg2, offset=1 ,color='g')\n",
      "plt.axis('tight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Concatenate all arrays\n",
      "concats = np.array([])\n",
      "for asig in seg2.analogsignals:\n",
      "    concats = np.hstack([concats, asig.magnitude])\n",
      "    \n",
      "# Build concatenated signal\n",
      "concat_sig2 = neo.AnalogSignal(\n",
      "    concats * pq.mV,\n",
      "    t_start = seg2.analogsignals[0].t_start,\n",
      "    sampling_period = seg2.analogsignals[0].sampling_period)\n",
      "    \n",
      "# STUDENTS\n",
      "plt.figure\n",
      "plt.suptitle('LFP 2 power spectrum', size=18)\n",
      "(p2,f2) = matplotlib.mlab.psd(concat_sig2.magnitude, NFFT=256, Fs=sf1)\n",
      "plt.semilogy(f2,p2)\n",
      "plt.xlim([1,100])\n",
      "plt.xlabel('f (Hz)', size=16)\n",
      "plt.ylabel('power density (1/Hz)', size=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, asig in enumerate(seg2.analogsignals):\n",
      "    (ptr2temp, ftr2, ttr2) = matplotlib.mlab.specgram(asig, NFFT=256, noverlap=250, Fs=sf1)\n",
      "\n",
      "    if i==0:\n",
      "        ptr2 = ptr1temp.copy()\n",
      "    else:\n",
      "        ptr2 = ptr1 + ptr1temp\n",
      "\n",
      "x_min = seg2.analogsignals[0].t_start.rescale('ms').magnitude\n",
      "ttr2 = ttr2 * 1000. + x_min\n",
      "ptr2 = ptr2 / len(seg2.analogsignals)\n",
      "\n",
      "plt.figure()\n",
      "plt.suptitle('LFP 2 spectrogram', size=18)\n",
      "plt.pcolor(ttr2, ftr2, np.log(ptr2))\n",
      "plt.xlabel('t ({0})'.format(asig.t_start.dimensionality), size=16)\n",
      "plt.ylabel('f (Hz)', size=16)\n",
      "plt.axis('tight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Coherence"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's investigate the coherency between the two electrodes. Use the function\n",
      "\n",
      "    matplotlib.mlab.cohere()\n",
      "\n",
      "to calculate the coherence between the two LFPs. As above, you may concatenate all trials of lfp1 and lfp2 into two long vectors, respectively, in order to easily obtain a trial average estimate of the coherence. \n",
      "- Plot the coherence obtained by this function as a function of frequency. How does the coherence plot compare to the power spectra, and why?\n",
      "- Vary the parameter `NFFT` of the `cohere` function and observe how the spectral estimate depends on the resolution of the number of points considered in the Fourirer transforms."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENT\n",
      "plt.figure\n",
      "plt.suptitle('LFP coherence between neighbouring electrodes', size=18)\n",
      "(c12, f12) = matplotlib.mlab.cohere(concat_sig1, concat_sig2, Fs=sf1, NFFT=128)\n",
      "plt.plot(f12, c12)\n",
      "plt.xlabel('f (Hz)', size=16)\n",
      "plt.ylabel('coherence', size=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Are some trials more coherent than others? Check this hypothesis by calculating a histogram (Hint: `plt.hist()`) of trial-by-trial coherence values at a frequency $f$=16 Hz. (Hint: you may find `np.argmin()` and `np.abs()` useful to find the corresponding adequate frequency bin in the `freqs` vector, see above)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trialbytrial_c=[]\n",
      "for asig1, asig2 in zip(seg1.analogsignals, seg2.analogsignals):\n",
      "    (c12, f12) = matplotlib.mlab.cohere(asig1.magnitude, asig2.magnitude, Fs=sf1, NFFT=256)\n",
      "    trialbytrial_c.append(c12)\n",
      "    \n",
      "#STUDENTS\n",
      "# Find index for 16 Hz\n",
      "fpos = np.argmin(np.abs(f12 - 16.))\n",
      "\n",
      "#STUDENTS\n",
      "plt.figure\n",
      "plt.suptitle('Coherence histogram at f={0} Hz'.format(f12[fpos]), size=18)\n",
      "plt.hist(np.array(trialbytrial_c)[fpos, :])\n",
      "plt.xlabel('coherence', size=16)\n",
      "plt.ylabel('trial count', size=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Maybe the coherence is higher during periods where the beta (here about 16 Hz) power is strong? To this end, cut your signal in a time range with strong beta power (check the spectrogram above!) using the `AnalogSignal.time_slice(from, to)` method. You may need to adjust `NFFT` of the `cohere()` function if your data cut-out is too small. Recalculate the histogram! Are values on average higher than expected?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS\n",
      "trialbytrial_c = []\n",
      "for asig1, asig2 in zip(seg1.analogsignals, seg2.analogsignals):\n",
      "    (c12, f12)=matplotlib.mlab.cohere(\n",
      "        asig1.time_slice(-250*pq.ms, 1800*pq.ms).magnitude,\n",
      "        asig2.time_slice(-250*pq.ms, 1800*pq.ms).magnitude, Fs=sf1, NFFT=256)\n",
      "    trialbytrial_c.append(c12)\n",
      "    \n",
      "#STUDENTS\n",
      "# Find index for 16 Hz\n",
      "fpos = np.argmin(np.abs(f12 - 16.))\n",
      "\n",
      "#STUDENTS\n",
      "plt.figure\n",
      "plt.suptitle('Coherence histogram at f={0} Hz'.format(f12[fpos]), size=18)\n",
      "plt.hist(np.array(trialbytrial_c)[fpos, :])\n",
      "plt.xlabel('coherence', size=16)\n",
      "plt.ylabel('trial count', size=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Desipite the promising results regarding the coherence across the complete trial, you may find the result on the partial trial unexpected -- indeed we need to be careful and suspicious here. \n",
      "\n",
      "- Invesitgate the interplay of the length of the data pieces you use (i.e., trials), the sampling frequency, the `NFFT` parameter and the width of the frequency bin you look at. \n",
      "- Why is our analysis flawed here?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Space for answer*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Look closely at the $z$-transformed LFP traces obtained earlier. Are the signals aligned, or phase-shifted? To examine this question in detail, let's calculate the phase differences of the coherence spectrum between the two recordings. For this analysis, we cannot rely on the current implementation of the coherence function in the numpy/scipy/mlab stack, because its output already has the phase information canceled out. Thus, for a thorough analysis, several advanced signal processing toolboxes exist providing good spectral estimators (e.g., the `nitime` toolbox).\n",
      "\n",
      "Instead, we will here program our own *poor-man's version* of a cross-spectral density using the intrinsic Fourier transform functions of scipy. Remember that the cross-spectrum is a complex valued function of frequency, its angle in the complex plane indicating the average phase shift between the two signals:\n",
      "$$C_{XY}=S_X(f)S^*_Y(f)=s_X(f)s_Y(f)e^{i\\phi_X(f)}e^{-i\\phi_Y(f)}=s_X(f)s_Y(f)e^{i(\\phi_X(f)-\\phi_Y(f))}=s_X(f)s_Y(f)e^{i\\Delta\\phi(f)},$$\n",
      "where $S_X$ and $S_Y$ are the Fourier transforms of two signals $X$ and $Y$. \n",
      "\n",
      "We will start by calculating cross spectra $C_{XY}$ on a trial-by-trial basis and then average them. Concatenating the trials like we did above is in principle possible, but will lead to a very poor estimate of the spectra due to the large number of data points and requires a smarter approach to obtain the spectral estimates (such as internally performed by functions such as the `psd` used above).\n",
      "\n",
      "- Calculate the discrete FFT (fast Fourier transform) for LFP 1 and 2 of the first trial using `np.fft.fft()`. The output of this function is a vector containing the FFT for positive and negative frequencies.\n",
      "- Check and plot the output of the `fft` function using `fft1.dtype` (data type): you will notice that the FFT functions give the complex Fourier transform contributions both positive and negative frequencies (Hint: To retrieve the real and imaginary parts of a complex number, use `np.real()` and `np.complex()`). The vector of frequencies corresponding to the bins of the output vector of `fft()` can be obtained using the function `np.fft.fftfreq()`. Inputs to the `fftfreq` function are: length of each trial in number of samples as parameter `n`, and sampling period as parameter `d`. Print the result of this function: how are the values ordered? \n",
      "- Remove the negative frequencies from the calculated FFT vectors of LFP 1 and 2, and from the frequency vector. Thus, the two resulting vectors will be only half as long as their original size. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "asig1 = seg1.analogsignals[0]\n",
      "asig2 = seg2.analogsignals[0]\n",
      "#Fourier transforms\n",
      "fft1 = np.fft.fft(asig1.magnitude)\n",
      "fft2 = np.fft.fft(asig2.magnitude)\n",
      "\n",
      "# show type of fft1\n",
      "print fft1.dtype\n",
      "\n",
      "# Show freqs vector\n",
      "freqs = np.fft.fftfreq(len(fft1), d=1.0/sf1)\n",
      "print freqs\n",
      "\n",
      "plt.figure()\n",
      "plt.suptitle('Fourier spectrum of trial 1 for LFP 1', size=18)\n",
      "freqs = np.fft.fftfreq(len(fft1), d=1.0/sf1)\n",
      "plt.plot(freqs, np.real(fft1))\n",
      "plt.plot(freqs, np.imag(fft1))  \n",
      "plt.xlabel('Frequecy (Hz)', size=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fft1 = fft1[0:len(fft1)/2]\n",
      "fft2 = fft2[0:len(fft2)/2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Now, multiply frequency-by-frequency (bin by bin) each of the FFT vector of LFP 1 by their respective complex conjugate (`numpy.conjugate()`) to obtain an estimate of the power spectral density. In the same fashion, calculate the power spectral density of LFP 2. Plot the spectra -- do they resemble the previous ones?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS\n",
      "ps1 = fft1 * np.conjugate(fft1)\n",
      "ps2 = fft2 * np.conjugate(fft2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- For each trial multiply the FFT of LFP 1 by the complex conjugate of the FFT of LFP 2 to obtain the cross spectral density. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS\n",
      "cs = fft1 * np.conjugate(fft2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Finally, average the power $P_X$ and $P_Y$ across all trials and likewise the cross-spectral densities $C_{XY}$ across all trials.\n",
      "- Combine the previous analysis steps into a function that calculates and returns the two power spectra and the complex values cross spectrum trial-by-trial and averages them. The function should return the "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS: Fill in the missing gaps (X)\n",
      "def get_coherence(seg1, seg2):\n",
      "    first_run = True\n",
      "    for asig1, asig2 in zip(seg1.analogsignals, seg2.analogsignals):\n",
      "        #X Fourier transforms\n",
      "        fft1 = np.fft.fft(asig1)\n",
      "        fft2 = np.fft.fft(asig2)\n",
      "        freqs = np.fft.fftfreq(len(fft1), d=1.0/sf1)\n",
      "        \n",
      "        # Remove negative frequencies\n",
      "        fft1 = fft1[1:len(fft1)/2]\n",
      "        fft2 = fft2[1:len(fft2)/2]\n",
      "        freqs = freqs[1:len(freqs)/2]\n",
      "        \n",
      "        #sum across trials\n",
      "        if first_run:\n",
      "            #X\n",
      "            ps1 = fft1 * np.conjugate(fft1)\n",
      "            ps2 = fft2 * np.conjugate(fft2)\n",
      "            cs = fft1 * np.conjugate(fft2)\n",
      "            first_run = False\n",
      "        else:\n",
      "            #X\n",
      "            ps1 = ps1 + fft1 * np.conjugate(fft1)\n",
      "            ps2 = ps2 + fft2 * np.conjugate(fft2)\n",
      "            cs = cs + fft1 * np.conjugate(fft2)\n",
      "    #average\n",
      "    cs = cs / lfpmat1.shape[0]\n",
      "    ps1 = ps1 / lfpmat1.shape[0]\n",
      "    ps2 = ps2 / lfpmat1.shape[0]\n",
      "        \n",
      "    return cs, np.real(ps1), np.real(ps2) ,freqs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Now first plot the (trial-averaged) power spectra of LFP 1 and LFP 2. How does this poor version compare to the more sophisticated estimates calculated in task 2 of this exercise?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cs, ps1, ps2, freqs = get_coherence(seg1, seg2)\n",
      "plt.figure()\n",
      "plt.suptitle(\"Poor man's power spectral density (LFP1/2 average)\", size=18)\n",
      "plt.semilogy(freqs, np.sqrt(ps1**2 + ps2**2))\n",
      "plt.xlabel('f (Hz)', size=16)\n",
      "plt.ylabel('PSD -- by hand', size=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Finally, plot as a function of frequency the absolute value of the cross-spectral density $C_{XY}$ (Hint: `np.abs()` returns the absolute value of a complex number), the coherency ($\\sigma=C_{XY}/(P_XP_Y)$) and the phase shift $\\Delta\\phi(f)$ (obtained as the angle of the cross spectral density (Hint: `np.angle()` returns the angle of a complex number). For the prominent beta frequency band $f$=16 Hz, what is the phase shift in degrees, and which LFP signal is lagging the other? (Hint: you may find `np.argmin()` and `np.abs()` useful to find the corresponding adequate frequency bin in the `freqs` vector, see above)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS\n",
      "plt.figure()\n",
      "plt.suptitle('Frequency-by-frequency cross-spectral density', size=18)\n",
      "plt.semilogy(freqs, np.abs(cs))\n",
      "plt.xlabel('f (Hz)', size=16)\n",
      "plt.ylabel('coherency', size=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS\n",
      "plt.figure()\n",
      "plt.suptitle('Frequency-by-frequency coherency', size=18)\n",
      "plt.plot(freqs, np.abs(cs) / np.sqrt(np.abs(ps1) * np.abs(ps2)))\n",
      "plt.xlabel('f (Hz)', size=16)\n",
      "plt.ylabel('coherency', size=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#STUDENTS\n",
      "plt.figure\n",
      "plt.suptitle('Frequency-by-frequency coherence phase difference', size=18)\n",
      "plt.plot(freqs, np.angle(cs))\n",
      "plt.xlabel('f (Hz)', size=16)\n",
      "plt.ylabel('phase difference', size=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Further tasks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- To make a better estimate of your spectral densities, you may want to window each LFP trial by a Hanning window (or some other windowing function) that consists of the same number of samples as in the LFP trial. This can be achieved by an element-wise multiplication of the two LFPs by the `scipy.signal.hann()` function. Plot the Hanning function. Does it improve your estimates?\n",
      "- You may want to explore this issue further: Assume the observed phase shifts are caused by a wave of LFP activity propagating across cortex. Given the electrode distance of about 400 microns, the frequency of the beta oscillation and the measured phase shift -- what is the approximate propagation speed?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Acknowledgements"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data are courtesy of Dr. Alexa Riehle, Institut de Neurosciences de la Timone (INT), UMR 7289, CNRS - Aix Marseille Univ., Marseille, France."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}